{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a new model with transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util import Retry\n",
    "\n",
    "# Scientific package imports\n",
    "import imageio\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Utils import\n",
    "from shutil import copy\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "import cgi\n",
    "import tempfile\n",
    "\n",
    "# AxonDeepSeg imports\n",
    "try:\n",
    "    from AxonDeepSeg.ads_utils import download_data\n",
    "except ModuleNotFoundError:\n",
    "    # Change cwd to project main folder \n",
    "    os.chdir(\"..\")\n",
    "    try :\n",
    "        from AxonDeepSeg.ads_utils import download_data\n",
    "    except:\n",
    "        raise\n",
    "except:\n",
    "    raise\n",
    "# If no exceptions were raised import all folders        \n",
    "from AxonDeepSeg.config_tools import validate_config\n",
    "from AxonDeepSeg.train_network import train_model\n",
    "from AxonDeepSeg.apply_model import axon_segmentation\n",
    "import AxonDeepSeg.ads_utils as ads\n",
    "\n",
    "# reset the tensorflow graph for new training\n",
    "tf.reset_default_graph()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  folder containing training data\n",
    "path_training = Path(\"./training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path of the init model for tranfer learning (TEM)\n",
    "dir_name_init = Path(\"default_TEM_model\")\n",
    "path_model_init = \"../AxonDeepSeg/models/\" / dir_name_init\n",
    "\n",
    "# Define file name of network configuration\n",
    "file_config = 'config_network.json'\n",
    "\n",
    "# Load config file from init model\n",
    "fname_config = os.path.join(path_model_init, file_config)\n",
    "if os.path.exists(fname_config):\n",
    "    with open(fname_config, 'r') as fd:\n",
    "        config = json.loads(fd.read())\n",
    "else:\n",
    "    print(\"config file doens't exists\")\n",
    "    \n",
    "print(\"The model used to init the config and weights is : \" + str(path_model_init.resolve().absolute()))\n",
    "\n",
    "# Define path to where the trained model will be saved\n",
    "dir_name = Path(config[\"trainingset\"] + '_' + time.strftime(\"%Y-%m-%d\") + '_' + time.strftime(\"%H-%M-%S\"))\n",
    "path_model = \"../models\" / dir_name\n",
    "\n",
    "# Create directory new model\n",
    "if not os.path.exists(path_model):\n",
    "    os.makedirs(path_model)\n",
    "\n",
    "# Set number of epochs for new training\n",
    "config[\"epochs\"] = 1000\n",
    "    \n",
    "# Save config new model\n",
    "fname_config = os.path.join(path_model, file_config)\n",
    "with open(fname_config, 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "\n",
    "print(\"This training session's model will be saved in the folder: \" + str(path_model.resolve().absolute()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4. Launch the training procedure\n",
    "\n",
    "The training can be launched by calling the *'train_model'* function. After each epoch, the function will display the loss and accuracy of the model. The model checkpoints will be saved according to the \"checkpoint_period\" parameter in \"config\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the tensorflow graph for new testing\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Train model\n",
    "train_model(str(path_training), str(path_model), config, path_model_init=path_model_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5. Monitor the training with Tensorboard\n",
    "\n",
    "[TensorBoard](https://www.tensorflow.org/guide/summaries_and_tensorboard) can be used to monitor the training procedure (loss and accuracy graphs, gradients, activations, identify bugs, etc.). To run TensorBoard, activate ADS virtual environment and run:\n",
    "```\n",
    "tensorboard --logdir PATH_MODEL --port 6006\n",
    "```\n",
    "where `PATH_MODEL` corresponds to this notebook's `path_model` variable (folder where model is being trained), and `port` is the port number where the TensorBoard local web server will be sent to (e.g., port 6006). Once the command is run, open a web browser with the address:\n",
    "```\n",
    "http://localhost:6006/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6. Resume training from checkpoint\n",
    "\n",
    "To resume training from a checkpoint, change the \"checkpoint\" parameter in \"config\" from None to \"loss\" or \"accuracy\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_model = \"../models/Path_of_the_model\" # Path of the model where the checkpoint is saved\n",
    "\n",
    "# train_model(str(path_training), str(path_model), config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Test the trained model\n",
    "#### 2.1. Set the path of the test image to be segmented with the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the lines below to use your image\n",
    "path_img = Path(\"../data\")\n",
    "file_img = \"image.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Launch the image segmentation\n",
    "\n",
    "The target resolution of the current version of the models are 0.1 for the **'default_SEM_model'** and 0.01 for the **'default_TEM_model'**. In this case, our test sample is a TEM brain sample of the mouse, so we set resampled_resolutions to 0.01.\n",
    "\n",
    "For your own trained model, use a resampled_resolutions corresponding to the general_pixel_size that was set in the 01-guide_dataset_building notebook in section 1.1. \"Define the parameters of the patch extraction\" when you created the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the tensorflow graph for new testing\n",
    "tf.reset_default_graph()\n",
    "prediction = axon_segmentation(path_img, file_img, path_model, config, acquired_resolution=0.1, resampled_resolutions=0.1, verbosity_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Display the resulted segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_img_seg = 'AxonDeepSeg.png'  # axon+myelin segmentation\n",
    "\n",
    "img_seg = ads.imread(path_img / file_img_seg)\n",
    "img = ads.imread(path_img / file_img)\n",
    "# Note: The arguments of the two function calls above use the pathlib syntax for path concatenation.\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(13,10))\n",
    "ax1, ax2 = axes[0], axes[1]\n",
    "ax1.set_title('Original image')\n",
    "ax1.imshow(img, cmap='gray')\n",
    "ax2.set_title('Prediction with the trained model')\n",
    "ax2.imshow(img_seg,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
